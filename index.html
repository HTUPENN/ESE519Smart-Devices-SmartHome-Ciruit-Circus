<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ESE519_FP_SmartHome_CircuitCircus</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 20px;
            padding: 0;
        }
        header, section, footer {
            margin-bottom: 20px;
        }
        h1, h2 {
            color: #007ACC;
        }
        h3 {
        color: #007ACC; /* 这里是图片中蓝色的颜色代码 */
        }
        img {
            max-width: 100%;
            height: auto;
        }
        video {
            display: block;
            margin: 10px 0;
            width: 100%;
            max-width: 600px;
        }
    </style>
</head>
<body>
    <header>
        <h1>Smart Home!</h1>
    </header>


    <!-- Team Information -->
    <section class="team-info">
        <h2>Team Information</h2>
        <p><strong>Team Name:</strong> Circuit Circus</p>
        <p><strong>Team Members:</strong> Hao Tan, Qingyang Xu, Ruizhe Wang</p>
        <p><strong>GitHub Repository:</strong> 
            <a href="https://github.com/upenn-embedded/final-project-circuit-circus.git" target="_blank">
                https://github.com/upenn-embedded/final-project-circuit-circus.git
            </a>
        </p>
    </section>

    <!-- 0. Video of the Final Product -->
    <section>
        <h2>Fianl Demo Video</h2>
        <p>Click to watch the video:</p>
        <a href="https://youtu.be/YMLCRkXXhso" target="_blank">
            <img src="videocover.jpg" alt="Video Thumbnail" style="width: 100%; max-width: 560px;">
        </a>
    </section>


        <!-- 1. Discription -->
    <section>
        <h2>Discription</h2>
        <p>This project was a significant learning experience in IoT system design, integrating hardware and software to create an intelligent, automated home. This IoT-based smart home system capable of automating multiple home appliances and transmitting real-time data to a smartphone app for bidirectional control. The system integrates a variety of sensors, motors, and communication protocols, enabling responsive and customizable functionality. The core control logic was programmed into an ATmega328PB Xplained Board, which communicates with an ESP32 microcontroller via SPI, and data is further transmitted to the Blynk cloud through MQTT.</p>
    </section>



    <!-- 2. Images  -->
    <section>
        <h2>Images</h2>
        <p>The below figures illlustrated the segment and whole system circuitry, where we used ATmega328PB as the manipulator programmed in bare metal C, and ESP32-FeatherS2 as the communication station to receive manipulator's feedback via SPI and publish to the IoT cloud(Blynk cloud) and deliver remote control demand from the user(typical Blynk app) back to the manipulator.</p>
        <img src="one_part.jpg" alt="Segment system circuitry">
        <img src="whole_system.jpg" alt="The whole Smart home">
    </section>

    <!-- 3. SRS Validation -->
    <section>
        <h2>SRS Validation</h2>
    </section>

    <section>
        <h3>SRS01: Sensors' driving, reading and sensor-based acuator control</h3>
    </section>

 <section>
    <h4>1: Light Sensor (BH1750) with Curtain Motor</h4>
    <p><strong>Communication Protocol:</strong> The BH1750 communicates with the microcontroller using the I2C protocol to transfer lux data.</p>
    <p><strong>Data Transfer and Motor Driver:</strong> Lux data is transfered via I2C, and sent to Atmega328PB which set signals to control the curtain motor.</p>
    <p><strong>Control Logic:</strong></p>
    <ul>
        <li>Low Lux (< 200): Indicates nighttime; the curtain is closed using the motor (<code>motor_backward</code>).</li>
        <li>Moderate Lux (200–3000): Indicates daytime; the curtain is opened using the motor (<code>motor_forward</code>).</li>
    </ul>
</section>

<section>
    <h4>2: Gyroscope Sensor (GY521) with LED and buzzer</h4>
    <p><strong>Communication Protocol:</strong> The GY521 communicates with the microcontroller using the I2C protocol, providing acceleration data across x, y, and z axes.</p>
    <p><strong>Data Transfer and LED Driver:</strong> Acceleration data is processed via I2C, and sent to Atmega328PB which light the LED through GPIO pins and sound a buzzer using PWM GPIO.</p>
    <p><strong>Control Logic:</strong></p>
    <ul>
        <li>Acceleration exceeds 1.50g: An earthquake is detected, and the LED and buzzeralarm is activated. (Simulations use 1.5g to prevent false triggers; theoretical threshold is 1.02g.)</li>
    </ul>
</section>

<section>
    <h4>3: Smoke Sensor (MQ-9B) with Buzzer Alarm and Fan</h4>
    <p><strong>Communication Protocol:</strong> The MQ-9B outputs an analog signal representing the concentration of smoke or harmful gases, which is read via the ADC on the microcontroller.</p>
    <p><strong>Data Transfer and Actuator Driver:</strong> Sensor data is converted to digital form via the ADC, and control signals are sent to the buzzer and fan via GPIO and motor driver function in Atmega328PB.</p>
    <p><strong>Control Logic:</strong></p>
    <ul>
        <li>Low Smoke (< 50 ppm): Normal air quality; no action is taken.</li>
        <li>High Smoke (> 200 ppm): Hazardous levels; the buzzer emits a continuous alarm, and the fan turns on for ventilation.</li>
    </ul>
</section>

<section>
    <h4>4: Humidity Sensor (DHT11) with Automatic Windom Motor (SG90)</h4>
    <p><strong>Communication Protocol:</strong> The DHT11 uses a simple one-wire protocol to communicate with the microcontroller.</p>
    <p><strong>Data Transfer and Motor Driver:</strong> Humidity data is transferred via the one-wire protocol, and control signals are sent to the SG90 motor through a motor driver funtion.</p>
    <p><strong>Control Logic:</strong></p>
    <ul>
        <li>Low Humidity (< 30%) and Moderate Lux (> 200): Sunny conditions; The window open.(<code>motor at 0 degrees</code>)</li>
        <li>High Humidity (> 80%): Excessive moisture; The window close. (<code>motor at 90 degrees</code>).</li>
    </ul>
</section>

<section>
    <h4>5: PIR Sensor (HC-SR501) with Buzzer and LED</h4>
    <p><strong>Communication Protocol:</strong> The HC-SR501 outputs a digital high/low signal to the microcontroller, indicating motion detection status.</p>
    <p><strong>Data Transfer and Actuator Driver:</strong> Motion detection signals are received via GPIO pins, and the buzzer and LED are controlled through GPIO outputs.</p>
    <p><strong>Control Logic:</strong></p>
    <ul>
        <li>No Motion Detected: Both buzzer and LED remain off.</li>
        <li>Motion Detected: The buzzer emits an alert sound, and the LED flashes to indicate intrusion.</li>
    </ul>
</section>


    <h3>SRS 02: Task Integration, Sensor-Based Actuator Control</h3>
    <ul>
        <li>
            <strong>Temperature & Humidity Sensor + Light Sensor:</strong> 
            Integrated to control the curtain step motor based on environmental conditions.
        </li>
        <li>
            <strong>Light Sensor:</strong> Used to control the LED stripe for ambient lighting adjustments and auto-curtain.
        </li>
        <li>
            <strong>Temperature & Humidity Sensor:</strong> Used to control the window NEMA 17 step motor for automated window adjustments.
        </li>
        <li>
            <strong>Smoke Sensor:</strong> Used to control the KY-012 sounder and fan, providing ventilation and alarms in hazardous conditions.
        </li>
        <li>
            <strong>Gyroscope:</strong> Used to trigger the KY-012 sounder during seismic events, simulating earthquake alarms.
        </li>
        <li>
            <strong>Human Sensor (PIR Motor):</strong> Used to control the KY-012 sounder for intrusion detection, emitting an audible alarm upon unauthorized motion.
        </li>
    </ul>


</section>

    <!-- 4. HRS Validation -->
    <section>
        <h2>HRS Validation</h2>
        <h4>Noted: All the detailed tested data from the sensor and some test videoes refer to: <a href="https://github.com/upenn-embedded/final-project-circuit-circus/blob/main/README.md">How we test? Collected data, images and videoes (Search Requirements Specification(HRS) Achievement on the Readme)</a> </h4>    
    
        <h4>Remotely Control skip to 1:14 and 6:31 in the <a href="https://www.youtube.com/watch?v=YMLCRkXXhso">Fianl Demo Video</a> at top;</h4>    
        

    <section>
        <h3>HRS01: Humidity Sensor (DHT11) with Automated Window Control</h3>
        <p><strong>Automated Control:</strong> The system automatically closes or opens the windows using a NEMA 17 step motor when the detected humidity exceeds or falls below a set threshold and rain is detected.</p>
        <p><strong>Remote Control and Monitoring:</strong> Humidity and temperature data are displayed in the Blynk app, allowing users to monitor environmental conditions and remotely control the windows (open/close) via the app.</p>
        <p><strong>Validation:</strong> The system was tested in both high- and low-humidity environments. In a high-humidity setup, the window closed automatically, and in a low-humidity setup, the window opened. For demonstration video, skip to 2:28 in the Fianl Demo Video at top</p>
    </section>

    <!-- Light Sensor -->
    <section>
        <h3>HRS02: Light Sensor (BH1750) with Automated Lighting and Curtain Control</h3>

        <p><strong>Automated Control:</strong> The system adjusts to changing light conditions. As outdoor light decreases (indicating evening), it gradually turns on LEDs (ws2812) for ambient lighting and closes the curtains using a step motor. Conversely, as outdoor light increases (indicating morning), the curtains automatically open. Curtain motor is connected to a H-bridge to control the close/open of the curtain through Through our curtain-motor driver function</p>

        <p><strong>Validation:</strong> The system was tested under varying light intensities to simulate day and night conditions. Proper functionality of both the LEDs and curtain motors was verified. For demonstrations, refer to the following timestamps in the Fianl Demo Video:
        <ul>
            <li>Auto Ambient Lighting: Skip to 5:58</li>
            <li>Auto Curtain Control: Skip to 6:54</li>
        </ul>
        </p>
    </section>



    <!-- Motion Sensor -->
    <section>
        <h3>HRS03: Motion Sensor (PIR HC-SR501) with Intrusion Detection</h3>

        <p><strong>Automated Control:</strong> When unauthorized motion is detected near the entrance, the system automatically activates a buzzer and LED alarm to notify of potential intrusion.</p>

        <p><strong>Validation:</strong> The system was tested by simulating motion near the sensor. Both the buzzer and LED alarm were confirmed to activate as expected. The test setup and results were recorded in video format. Refer to the demonstration video at timestamp 4:52 for details.</p>


    </section>


        <!-- Smoke Sensor -->
    <section>
      <h3>HRS04: Fresh Air System with Smoke Sensor (MQ-9B) and Smoke Detection and Alarm</h3>

        <p><strong>Automated Control:</strong> When smoke levels exceed a safe threshold, the system automatically activates a 5V exhaust fan to ventilate the area and triggers a smoke alarm using a buzzer for immediate notification.</p>

        <p><strong>Validation:</strong> The system was tested under simulated smoke conditions. Both the fan activation and buzzer alarm were verified to function correctly. For a demonstration, refer to the Final Demo Video at the top, timestamp 3:41.</p>

    </section>

    <!-- Gyroscope/Vibration Sensor -->
    <section>
        <h3>HRS05: Gyroscope/Vibration Sensor (GY521) with Earthquake Detection</h3>

        <p><strong>Automated Control:</strong> When seismic activity, such as an earthquake, is detected, the system automatically triggers an earthquake alarm, activating both a buzzer and an LED to alert users.</p>

        <p><strong>Validation:</strong> The system was tested by simulating vibration conditions to mimic seismic activity. The buzzer and LED alarm were confirmed to activate correctly. For a demonstration, refer to the video at timestamp 5:32.</p>
    </section>


    <!-- Remotely Controlled Door -->
    <section>
        <h3>HRS06: Remotely Controlled Door with SG90 Motor</h3>


        <p><strong>Validation:</strong>The door can be open/closed via phone remotely. For a demonstration, refer to the video at timestamp 6:33.</p>

    <!-- IoT Control -->
    <section>
        <h3>HRS07: Remote IoT Control and Monitor: Blynk Integration</h3>
        <p><strong>Except the auto-controlling,</strong> Sensor data and motor/actuator states are transmitted to the ESP32 and published to the Blynk cloud, enabling remote monitoring and control via a smartphone app.</p>

        <p><strong>Validation:</strong>  Controlled motors and actuators through the app and confirmed synchronization with the physical system. The control process and state monitoring UI skip to 1:14 and 6:31</p>
    
    </section>

    <section>
    <h3>Performance Metrics and Shortcomings</h3>

    <h4>Performance Metrics</h4>
    <ul>
        <li><strong>Power Efficiency:</strong> The system operates within a power budget of 12V DC, supporting all sensors and actuators without significant voltage drops.</li>
        <li><strong>Component Responsiveness:</strong> Motors (e.g., NEMA 17, SG90) responded promptly to control signals, with activation times under 300ms.</li>
        <li><strong>Sensor Integration:</strong> All sensors (DHT11, MQ-9B, PIR, gyroscope) exhibited stable performance under various environmental conditions.</li>
    </ul>

    <h4>Shortcomings</h4>
    <ul>
        <li><strong>Smoke Sensor:</strong> Reduced sensitivity was observed when operating under extreme temperatures, necessitating recalibration to maintain accuracy.</li>
        <li><strong>Scalability Limitation:</strong> The reliance on wired SPI for microcontroller communication constrained the system's scalability for larger deployments.</li>
    </ul>
</section>



    </section>

    <!-- 5. Conclusion -->
    <section>
        <h2>Conclusion</h2>
        <p>This project was a significant learning experience in IoT system design, integrating hardware and software to create an intelligent, automated home. Key features include environmental monitoring (humidity, light, smoke, motion, and seismic activity), automated control of windows, curtains, and ventilation, intrusion detection, and seamless IoT-based remote control via the Blynk app. Communication between the ATmega328PB and ESP32 ensures real-time data synchronization, providing a responsive, user-friendly, and efficient smart home solution. This IoT-based smart home system capable of automating multiple home appliances and transmitting real-time data to a smartphone app for bidirectional control which integrates a variety of sensors, motors, and communication protocols, enabling responsive and customizable functionality. The core control logic was programmed into an ATmega328PB Xplained Board, which communicates with an ESP32 microcontroller via SPI, and data is further transmitted to the Blynk cloud through MQTT.</p>

        <h3>Lessons Learned</h3>
        <p> Through this project, we realized the importance of thorough testing to ensure sensor reliability under diverse conditions, which is vital for accurate system performance. We also learned to anticipate communication delays in IoT systems and the necessity of designing for fault tolerance to enhance system robustness. The integration process, involving numerous components, consumed significant time and effort, during which we encountered many challenging and hard-to-understand bugs and incompatibilities. These experiences deepened our understanding of embedded systems and equipped us to handle similar issues more effectively in the future.</p>

        <h3>Future Improvements</h3>
        <p>  To enhance scalability and flexibility, transitioning to wireless communication protocols like Wi-Fi or Zigbee would be beneficial. Incorporating machine learning algorithms could optimize device control by predicting user preferences, while adding energy-saving mechanisms such as solar-powered components would improve sustainability. Given the complexity of this smart home system, using a more powerful board or planning for multiple boards from the start would ensure better performance. In such cases, robust remote communication between boards should be prioritized. </p>

    </section>

    <footer>
        <p>Many thanks to Nicholas McGill-Gardner, Yadnik Bendale and all guys in this courses. </p>
        <p>Project by <a href="https://github.com/HTUPENN">HT</a>, <a href="https://github.com/RzWang0404">RZW</a>  , <a href="https://github.com/QingyangXu11">QYX</a></p>
    </footer>
</body>
</html>
